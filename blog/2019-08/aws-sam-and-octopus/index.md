---
title: Deploying AWS SAM Templates with Octopus
description: Learn how to integrate SAM templates with Octopus deployments for AWS serverless applications.
author: matthew.casperson@octopus.com
visibility: private
published: 2019-08-22
metaImage:
bannerImage:
tags:
 - Octopus
---

As patterns like microservices become increasingly popular, cloud providers are investing in serverless computing platforms way of managing and executing large numbers of small and independent applications. The AWS Serverless Application Model (AWS SAM) ties together the AWS services commonly used when deploying serverless applications. AWS SAM builds on CloudFormation, but removes a lot of the common boiler plate code to make deploying serverless applications quick and easy.

The AWS SAM CLI makes it very easy to get a serverless application up and running. In this blog post we'll look at how you can move from the proof of concept stage to repeatable deployments across multiple environments in Octopus.

## The Hello World App

We'll start with the Python Hello World application created with the SAM CLI tool. The process of creating this application is documented [here](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-getting-started-hello-world.html#serverless-getting-started-hello-world-initialize).

The sample code that is generated by the SAM CLI commands `sam init --runtime python3.7` and `sam build` has been committed to a GitHub repo [here](https://github.com/OctopusDeploy/AWSSamExample), and we'll use this repo as the starting point for our deployment process.

## Building the Application with Github Actions

If you follow the typical AWS SAM workflow, you will run a command like `sam package --s3-bucket <yourbucket>`, which will:

* Bundle up your source code with any dependencies.
* Upload the bundle to S3.
* Replace the `CoreUri` field in the SAM template with the location of the file in S3.

It is important to note that CloudFormation, and therefor SAM, does not deploy code from your local PC - everything has to be uploaded to S3. The benefit of the `sam package` command is that it automates most of the work for you, resulting in a processed template that you can then deploy with CloudFormation.

However the `sam package` command can be a little clunky when you need to implement repeatable deployments across multiple environments. The S3 file that is uploaded has a randomly generated name like `fecddec7c6c40bd9de28f1775cd11e0e`, which makes it nearly impossible to work out what code bundle was deployed for a given version. You are also responsible for keeping a copy of the processed template file (i.e. the one with the updated `CoreUri` field) around so you can track what templated deployed what code.

Or to [quote the SAM developers themselves](https://github.com/awslabs/aws-sam-cli/issues/648#issuecomment-419538378):

> Yes, "sam package" is rudimentary. Real solution is to create a better package command that will do content addressing better (may be using git sha, or content sha, or customer-provided naming function).

So we'll take a slightly different approach by managing the packaging, uploading and template updating ourselves. This will give us some sane file names, and create reusable templates. We'll implement this with GitHub Actions, and the workflow YAML is shown below.

```yaml
name: Python package

on: [push]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v1
    - name: Get Git Version
      uses: docker://mcasperson/gitversion:5.0.2-linux-centos-7-netcoreapp2.2
      with:
        args: /github/workspace /nofetch /exec /bin/sh /execargs "-c \"echo $GitVersion_FullSemVer > /github/workspace/version.txt\""
    - name: Set up Python 3.7
      uses: actions/setup-python@v1
      with:
        python-version: 3.7
    - name: Package dependencies
      # Permissions are documented at
      # https://docs.aws.amazon.com/lambda/latest/dg/deployment-package-v2.html
      run: |
        python -m pip install --upgrade pip
        cd hello_world
        pip download -r requirements.txt
        unzip \*.whl
        rm *.whl
        chmod 644 $(find . -type f)
        chmod 755 $(find . -type d)
    - name: Extract Octopus Tools
      run: |
        mkdir /opt/octo
        cd /opt/octo
        wget -O /opt/octo/octopus.zip https://download.octopusdeploy.com/octopus-tools/6.12.0/OctopusTools.6.12.0.portable.zip
        unzip /opt/octo/octopus.zip
        chmod +x /opt/octo/Octo
    - name: Pack Application
      run: |
        cd /home/runner/work/AWSSamExample/AWSSamExample/hello_world
        zip -r /home/runner/work/AWSSamExample/AWSSamExample/AwsSamLambda.$(cat /home/runner/work/AWSSamExample/AWSSamExample/version.txt).zip *
    - name: Push to Octopus
      run: >-
        /opt/octo/Octo push
        --server ${{ secrets.MATTC_URL }}
        --apiKey ${{ secrets.MATTC_API_KEY }}
        --package /home/runner/work/AWSSamExample/AWSSamExample/AwsSamLambda.$(cat /home/runner/work/AWSSamExample/AWSSamExample/version.txt).zip
        --overwrite-mode IgnoreIfExists
        --space Lambda
    - name: Pack Templates
      run: >-
        /opt/octo/Octo pack
        --outFolder /home/runner/work/AWSSamExample/AWSSamExample
        --basePath /home/runner/work/AWSSamExample/AWSSamExample
        --id AwsSamLambdaTemplates
        --version $(cat /home/runner/work/AWSSamExample/AWSSamExample/version.txt)
        --include s3bucket.yaml
        --include template.yaml
        --format zip
    - name: Push to Octopus
      run: >-
        /opt/octo/Octo push
        --server ${{ secrets.MATTC_URL }}
        --apiKey ${{ secrets.MATTC_API_KEY }}
        --package /home/runner/work/AWSSamExample/AWSSamExample/AwsSamLambdaTemplates.$(cat /home/runner/work/AWSSamExample/AWSSamExample/version.txt).zip
        --overwrite-mode IgnoreIfExists
        --space Lambda
```

There are two parts to this workflow that allow us to replicate the funcationality provided the the `sam package` command.

The first is where we download the Python dependencies, extract them, and set the [permissions on the files](https://docs.aws.amazon.com/lambda/latest/dg/deployment-package-v2.html).

```
- name: Package dependencies
  # Permissions are documented at
  # https://docs.aws.amazon.com/lambda/latest/dg/deployment-package-v2.html
  run: |
    python -m pip install --upgrade pip
    cd hello_world
    pip download -r requirements.txt
    unzip \*.whl
    rm *.whl
    chmod 644 $(find . -type f)
    chmod 755 $(find . -type d)
```

The second is where we create the zip file with a meaningful version number. If you look back at the workflow YAML you will see that we have generated this version number using GitVersion. The blog post [Adding versions to your GitHub Actions](https://octopus.com/blog/versioning-with-github-actions) goes into more detail about how this versioning works.

::hint
We use the `zip` tool to package up the Python code instead of the `octo` cli because AWS is very particular about the [permissions](https://docs.aws.amazon.com/lambda/latest/dg/deployment-package-v2.html) of files inside the zip file. The `zip` tool creates the correct permissions, whereas the `octo pack` command would result in a ZIP file that could not be deployed.

```yaml
- name: Pack Application
  run: |
    cd /home/runner/work/AWSSamExample/AWSSamExample/hello_world
    zip -r /home/runner/work/AWSSamExample/AWSSamExample/AwsSamLambda.$(cat /home/runner/work/AWSSamExample/AWSSamExample/version.txt).zip *
```

We create a second package to hold the templates. We have two templates here, and they will be covered in more detail later on.

```yaml
- name: Pack Templates
  run: >-
    /opt/octo/Octo pack
    --outFolder /home/runner/work/AWSSamExample/AWSSamExample
    --basePath /home/runner/work/AWSSamExample/AWSSamExample
    --id AwsSamLambdaTemplates
    --version $(cat /home/runner/work/AWSSamExample/AWSSamExample/version.txt)
    --include s3bucket.yaml
    --include template.yaml
    --format zip
```

These packages are then pushed to the Octopus server with jobs calling `octo push`.

At this point we have the application code and the templates uploaded to the Octopus server, ready to be deployed. We have replicated the bundling functionality of the `sam package` application, and the next step is to replicate the push to S3.

## Uploading the Package with Octopus

Before we push to S3, we will first create the bucket. This will be done with a standard CloudFormation template. In this template we will specify that files in this S3 bucket are removed after a certain amount of time.

Normally, the `sam package` command will push a file to S3 and leave it there for eternity. However once the file has been used to complete the deployment it is no required, and since these files cost us money it makes sense to clean them up after a period of time. If we ever need to redeploy a version of an application, Octopus will reupload the file.

```yaml
AWSTemplateFormatVersion: 2010-09-09
Description: Creates an S3 bucket that cleans up old files
Resources:
  CodeBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: "#{S3BucketName}"
      AccessControl: Private
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - NoncurrentVersionExpirationInDays: 3
            Status: Enabled
```

Note that the `BucketName` has been defined as an Octopus variable. The marker `#{S3BucketName}` will be replaced with the value of the `S3BucketName` variable during deployment.

This template is deployed with the `Deploy an AWS CloudFormation template` step.

The CloudFormation settings define the region and stack name as variables. This will be important as we move to deployments across multiple environments.

![](s3-bucket-cloudformation-settings.png "width=500")

The CloudFormation template is them sourced from the package called `AwsSamLambdaTemplates` which has the file called `s3bucket.yaml`.

![](s3-bucket-package-settings.png)

The application package is then uploaded with the `Upload a package to an AWS S3 bucket` step.

The only thing of note in this step is that we have again used a variables for the bucket name and AWS region.

![](s3-upload.png "width=500")

At this point we have now replicated the functionality of the `sam package` command by bundling up a self contained deployment using GitHub Actions, and pushing it to S3 using Octopus. We have also ensured that the packages we upload have readable names like `AwsSamLambda.0.1.0+71.zip` which clearly indicate the application and version that they contain. As you can see from the screenshot below, the packages uploaded by us (`AwsSamLambda.0.1.0+xx.zip`) offer a lot more context than the packages uploaded by `sam package` (`fecddec7c6c40bd9de28f1775cd11e0e`).

![](s3-console.png "width=500")

The next step is to deploy the SAM template.

# Deploying the Template with Octopus
