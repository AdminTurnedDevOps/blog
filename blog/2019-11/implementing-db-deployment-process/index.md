---
title: Implementing Automated Database Deployments Process
description: In this article, I will walk through the steps I took to implement an automated database deployment process using TeamCity, Redgate, and Octopus Deploy
author: bob.walker@octopus.com
visibility: public
published: 2019-11-13
metaImage: 
bannerImage: 
tags:
 - Engineering
 - Database Deployments
---

It took several iterations to implement the ideal automated database deployment process using TeamCity, Redgate, and Octopus Deploy.  The iterations were a result of learning the tooling and listening to feedback.  In this article, I am going to walk you through various iterations of the automated database deployment process.  

This article is a continuation of the article published yesterday.  Here are the links in the event you missed the other articles.  

- Designing Automated Database Deployments Process (link to be added later)
- Designing Automated Database Deployments Process Use Case (link to be added later)

All of our database deployment posts can be found [here.](https://octopus.com/database-deployments)

!toc

## General Overview
All this work was done at a company I previously worked for.  That company had four environments.

- Development
- Test
- Staging
- Production

Developers, Database Developers, and Lead Developers all had sysadmin rights on `Development` and `Test`.  They had read-only rights on `Staging` and `Production`.  Only the DBAs had sysadmin rights to all environments.

Prior to automated database deployments, delta scripts for `Staging` and `Production` were generated by Database Developers or Lead Developers.  The delta scripts would be saved on a file share for the DBAs.  The DBAs would run the script in the appropriate environment.

There were several flaws in this process.
- Two different processes, one for `Development` and `Test` and another for `Staging` and `Production`.
- Manual generation of scripts.
- Manual running of each script in each environment.
- Unique delta scripts per environment.
- Unique delta scripts meant it was difficult or near impossible to test.
- No mention of keeping track of changes and what needed to be deployed.
- Shared development environment.
- Reviews didn't happen until it was time to go to `Staging`.
- As a result, "All hands on deck" during `Production` deployments.

The tooling we were using when this started was:
- TFS for source control (some teams were piloting Git)
- TFS for build server (some teams were piloting TeamCity)
- No deployment server
- No database deployment tools (this is where Redgate's tooling came in)

## Automated Database Deployments v1
The first attempt at automating database deployments was designed to fit within the existing process.  I detailed the reasons why in my previous article (link here).  Thankfully, I was on one of the teams piloting Git and TeamCity.  However, the DBAs made it very clear, TeamCity would not have permission to deploy to `Staging` and `Production`.

Looking at the documentation for [Redgate's Team City Plug-in](https://documentation.red-gate.com/display/SCA3/Use+the+TeamCity+plugin+with+a+SQL+Change+Automation+Project) shows it supports three functions:

- Build a Package
- Sync that package with a database
- Test that package

For the build a package process to work, the database has to be placed into source control using [Redgate's SQL Source Control](https://documentation.red-gate.com/soc).  Also, Redgate has a [CLI version](https://documentation.red-gate.com/sc14/using-the-command-line) of their schema compare tool.

One thing I should've done was to resolve all the deltas between each environment.  Different users and role membership are expected.  Missing tables, different stored procedures, and other schema changes, not so much.  Once they are resolved, then pick an environment to put into source control as your baseline.

The deltas will need to be resolved one of three ways:
- The change was missed, go ahead and apply it.
- The change is intentional and should never be included in source control (backup table or testing table).  You can [leverage filters](https://www.codeaperture.io/2016/10/14/using-sql-source-control-to-filter-out-unwanted-items/) to exclude those items.
- The difference is environmental, such as users and role membership.  In that case, you would want to look at [the documentation](https://documentation.red-gate.com/sc13/using-the-command-line/options-used-in-the-command-line#Optionsusedinthecommandline-IgnorePermissions) to see what switches you need to include.  

Knowing that my plan of attack was:

0. Resolve all the deltas.
1. Put what is in `Development` into source control.  Going forward, all changes must be made in `Development` and checked into source control.
2. Have TeamCity build the package from source control.
3. Have TeamCity sync that package with `Development`.
4. Have TeamCity sync that package with `Test`.
5. Have TeamCity run the schema compare CLI to generate delta scripts for `Staging` and `Production`.

Steps 1 and 3 conflicts with each other.  So let's skip that step. 

0. Resolve all the deltas.
1. Put what is in `Development` into source control.  Going forward, all changes must be made in `Development` and checked into source control.
2. Have TeamCity build the package from source control.
3. ~~Have TeamCity sync that package with `Development`.~~
4. Have TeamCity sync that package with `Test`.
5. Have TeamCity run the schema compare CLI to generate delta scripts for `Staging` and `Production`.

I'm not going to walk through how to put a database into source control.  I wrote [that article already](https://www.red-gate.com/hub/product-learning/sql-source-control/database-version-control-2).  No need to rehash it.

I ended up with four TeamCity projects.

![](automated-database-deployments-v1-teamcity-overview.png)

The `00_Build` project takes what is in source control and packages it up.  

![](automated-database-deployments-v1-build-overview.png)

I am making use of TeamCity's [snapshot dependencies](https://www.jetbrains.com/help/teamcity/snapshot-dependencies.html) and artifact dependencies.  To leverage that, I need to mark the package created as an artifact.

![](automated-database-deployments-v1-artifacts.png)

`10_Dev` and `20_Test` follow the same process.  First, I needed to configure the dependencies on the build.  The dependencies includes the snapshot dependencies and artifact dependencies.

![](automated-database-deployments-v1-dependencies.png)

Now that I have the package and the dependency configured, I can add in the step to sync the `Test` database with the package.  Please note, to deploy the latest package, I am overriding build number using the value from the `00_Build` project.  

![](automated-database-deployments-v1-sync.png)

The `30_Staging` build is very different.  First, I configure the dependencies just like before.

![](automated-database-deployments-v1-staging-dependencies.png)

Instead of running the sync step, it runs a PowerShell script to generate the delta scripts for Staging and Production.

![](automated-database-deployments-v1-staging.png)

## Flaws with Automated Database Deployments v1

Let's revisit the flaws with the existing process and see how we are doing after going through this effort.

There were several flaws in this process.
- Two different processes, one for `Development` and `Test` and another for `Staging` and `Production`. -> Still happening.
- Manual generation of scripts. -> **Solved**
- Manual running of each script in each environment. -> Solved for `Test` only.
- Unique delta scripts per environment. -> Still happening
- Unique delta scripts meant it was difficult or near impossible to test. -> Still happening
- No mention of keeping track of changes and what needed to be deployed. -> **Solved**
- Shared development environment. -> Still happening
- Reviews didn't happen until it was time to go to `Staging`. -> Still happening
- As a result, "All hands on deck" during `Production` deployments. -> Less of a problem, but still happening

Also, I introduced a couple of new problems.

- Hours or days between when a script is generated by `30_Staging` and when it was run in `Staging` or `Production`.
- Hard to know what version is going to be used to generate the delta scripts when `30_Staging` ran.
- The latest changes only, can't pick an older version.

## New Process

In my previous article, I discussed how Redgate helped a workgroup at the company I was working for.  Let's review the process we came up with.

1. Developer/Database Developer/Lead Developer creates a branch.
2. All database changes and code changes are made on that branch.
3. Changes are completed and checked into the branch.
4. A merge request is created, which kicks off a build.  Build verifies the changes are valid SQL.
5. Database Developer or Lead Developer reviews database changes in the merge request.  Database Developer provides feedback for fixes.
6. The branch is approved and merged.
7. Build Server kicks off build.  Verifies the changes are valid SQL, and if they are, packages them up and pushes to Deployment Server.  Build Server tells Deployment Server to deploy to `Development`.
8. Deployment Server deploys to `Development`.
9. Developer/Database Developer/Lead Developer tells Deployment Server to deploy to `Test`.
10. Deployment Server deploys to `Test`.
11. Changes are verified in `Test`.
12. Developer/Database Developer/Lead Developer tells Deployment Server to deploy to `Staging`.  Deployment server uses database tooling to generate review script.
13. Deployment Server notifies DBA of deployment request to `Staging`.  They review the changes.  Provide feedback for fixes.
14. DBAs approve changes to `Staging`.
15. Deployment Server finishes deployment to `Staging`.
16. Changes are verified in `Staging`.  
17. A change request is submitted to the DBAs to promote a specific package in the deployment server to `Production`.
18. After hours, DBAs tell Deployment Server to deploy to `Production`.  Deployment server uses database tooling to generate review script.
19. DBAs review the script as a final sanity check.
20. Deployment Server finishes deployment to `Production`.

## Automated Database Deployments v2

Octopus Deploy was added to v2 of Automated Database Deployments.  TeamCity was simplified to two projects.  

![](automated-database-deployments-v2-teamcity-overview.png)

`00_Build` would build the package just like before.  `10_Dev` pushes that package and triggers a deployment in Octopus Deploy to `Development`.  [Our documentation](https://octopus.com/docs/packaging-applications/build-servers/teamcity#TeamCity-CreateAndPushPackageToOctopusCreatingandpushingpackagesfromTeamCitytoOctopus) does an excellent job of showing you how to do that.

![](automated-database-deployments-v2-teamcity-dev.png)

After a bit of trial and error, the deployment process in Octopus Deploy became this:

![](automated-database-deployments-v2-octopus-overview.png)

The trial and error were around steps 1 and 4.  At first, I was running the same CLI script from TeamCity to generate the delta script to review.  That wasn't the same as what was getting deployed.  Eventually, I learned about the `Create Database Release` and `Deploy from Database Release` step templates provided by Redgate.  

The bonus of using the Redgate provided step templates is it automatically generated and uploaded the delta scripts as [Octopus Artifacts](https://octopus.com/docs/deployment-process/artifacts).  DBAs could then download those files and review them when they were approving the deployment to `Staging` or `Staging`.

![](automated-database-deployments-v2-approve-release.png)

The DBAs were more than happy to let Octopus Deploy deploy to `Staging` and `Production`.  They could review the scripts during the deployment.  And who reviewed the scripts was audited.  Besides, they were happy to see all it took was a push of a button.  As one DBA put it "this is all stupid simple."

What sealed the deal was the ability to control who could push the deployment button.  All developers (including database developers and lead developers) could deploy to `Development`, `Test`, and `Staging`.

![](automated-database-deployment-v2-developer-permissions.png)

While the DBAs could deploy to `Production`.  But they didn't have the right to change the deployment process.  Only Developers could do that.

![](automated-database-deployment-v2-dba-permissions.png)

While developers could deploy to `Staging`, the DBAs were the ones who approved the changes.

![](automated-database-deployments-v2-dbas-approve.png)

These security policies and manual interventions built a lot of trust in the process.

## Flaws with Automated Database Deployments v2

Let's check back in with our issue list.

- Two different processes, one for `Development` and `Test` and another for `Staging` and `Production`. -> **Solved**
- Manual generation of scripts. -> **Solved**
- Manual running of each script in each environment. -> **Solved.**
- Unique delta scripts per environment. -> **Mitigated**, it is how the tool works.
- Unique delta scripts meant it was difficult or near impossible to test. -> **Mitigated**, but much less of a chance causing errors since the same process is used.
- No mention of keeping track of changes and what needed to be deployed. -> **Solved**
- Shared development environment. -> **Solved**
- Reviews didn't happen until it was time to go to `Staging`. -> **Solved**, Database Developers reviewed feature branch changes, DBAs reviewed in `Staging`.
- As a result, "All hands on deck" during `Production` deployments. -> **Solved**
- Hours or days between when a script is generated by `30_Staging` and when it was run in `Staging` or `Production`. -> **Solved**
- Hard to know what version is going to be used to generate the delta scripts when `30_Staging` ran. -> **Solved**
- The latest changes only, can't pick an older version. -> **Solved**

Fantastic, all the original problems, plus the problems with v1, were solved or mitigated.  But something interesting happened.  The process worked.  As the weeks went by, we started doing more and more deployments to `Production` and `Staging`.  

- As the process was written, the DBAs had to be on each `Production` deployment.  
- Developers had to wait until the DBAs finished reviewing their scripts in `Staging` prior to deployment.  The DBAs couldn't keep up.
- There was no test data in the developer's local databases; this resulted in them pushing unfinished changes to `Test`.  They'd then point their code to `Test` so they had data to test with.

## Automated Database Deployments v2.1 

The workgroup met, and we agreed to make the following changes to the process

- DBAs will only approve changes in `Staging`.
- Approval in `Staging` will occur after the deployment occurs.
- DBAs only want to be notified if deployment to `Production` fails.
- DBAs want to see the delta script for `Production` during the staging deployment.  It won't be 100% the same, but it will be close enough for them to review. 
- Generate a backup of `Test` after each deployment.  Developers could then restore the backup on their instance to get the testing data.

The resulting process looked like this:

![](automated-database-deployments-v2-1.png)

Once those changes were in place, DBAs could then leverage the `Deploy Later` functionality in Octopus Deploy.

![](automated-database-deployments-v2-1-schedule-release.png)

## Conclusion

After going through this process, deployments to `Production` became a non-event.  The DBAs only had to jump online during `Production` deployments when something failed, which became more and rarer.  It took several iterations to get there.

What surprised me the most was how much everything changed from start to finish.  I'll be honest; if I came across a customer with the final database deployment process, I'd have a lot of questions.  But it makes sense in the context of the company that implemented it.  It meets their requirements.  Don't be surprised by the number of iterations you make and where you will eventually end up.  Every company is different.

Happy Deployments!

If you enjoyed this article and would like to see more posts on automated database deployments please [click here.](https://octopus.com/database-deployments)