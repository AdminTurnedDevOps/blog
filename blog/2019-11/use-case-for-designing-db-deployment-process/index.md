---
title: Designing Automated Database Deployments Process Use Case
description: This article walks through the steps I went through to help design an automated database deployment process. 
author: bob.walker@octopus.com
visibility: public
published: 2019-11-05
metaImage: 
bannerImage: 
tags:
 - Engineering
 - Database Deployments
---

Prior to joining Octopus Deploy I was the lead developer on the pilot team which Automated Database Deployments to go from 2-4 hour deployments to 10 minute deployments.  When I started I thought we were going to automate steps in our existing process.  I started implementing the tooling to do just that.  Little did I know the entire process was going to change.

This article is a continuation of the article published yesterday.  Here are the links in the event you missed that article, or would like to skip ahead to the next article, where I provide a step-by-step guide on implementing the process with Octopus Deploy.

- Designing Automated Database Deployments Process Use Case
- Implementing a Database Deployment Process with Octopus Deploy

!toc

## Forming of the work group
One of the DBAs in the company summed it up best: "Our database deployment process is the wild west."  We had more developers joining the company every month.  New teams were forming.  More code was being deployed each day.  The issues with database deployments had to stop.  It was time to form a work group.  The DBAs and Database Architect all liked using Redgate's tooling, so they reached out to Redgate to help.  They identified the DBA who would represent them at the work group.  After Redgate agreed to help, my team was identified as the pilot team.  Redgate agreed to fly out two people in a couple of months to meet with the work group for two days.

Being naive, I thought Redgate was going to help us implement their tooling within our existing process.  I set about doing that.  My thought was Redgate could come in and tweak what I had already put together.  Little did I know the work group was going to throw away about 75% of what I created.  That wasn't a big deal, it was a good learning experience.  I had a better fundamental understanding of how database deployment tools work.  That helped me contribute during the kick-off meeting.

### Kick-Off Meeting
The database developer from my team, a DBA, a Database Architect, two Redgaters and I met for two days.  The first day was focused on designing our ideal process.  First, we needed to walk through the existing process.

1. Developer makes change in `Development`.  All Developers have sysadmin rights in `Development`.
2. Developer changes connection in SSMS and makes change to `Test`.  All Developers have sysadmin rights in `Test`.
3. Database Developer or Lead Developer runs Redgate Schema Compare to generate delta script for `Test` and `Pre-Prod`.  Any complex database changes (move columns, combine columns, etc) are removed and manually scripted.  Scripts are saved to a shared folder.  Everyone except DBAs have read-only rights to `Pre-Prod`, so DBAs have to run the scripts.  
4. DBAs are notified via email to run scripts in shared folder on `Pre-Prod`.  They run the scripts and send output to the requester.  
5. Multiple changes can be pushed to `Pre-Prod` prior to going to `Production`.  Because of that, a new Redgate Schema Compare delta script between `Pre-Prod` and `Production` is generated by the Database Developer or Lead Developer.  Just like before, any complex database changes (move columns, combine columns, etc) are removed and manually scripted.  Scripts are saved to a shared folder.  Everyone except DBAs have read-only rights to `Production`.

We tackled the questions next.

1. Who are the people involved in the process? -> Developers, Database Developer, Lead Developer, and DBAs
2. What permissions do they have? -> Developers, Database Developers and Lead Developers all have sysadmin rights in `Development` and `Test`.  DBAs have sysadmin rights in `Development`, `Test`, `Pre-Prod` and `Production`.
3. Why are they involved? -> Developers, Lead Developers and Database Developers make the changes to `Development` and `Test`.  Database Developers and Lead Developers create the delta scripts using Redgate Schema Compare.  DBAs deploy the delta scripts to `Pre-Prod` and `Production`
4. Which environments have a different process? -> There are two processes, deployments to `Development` and `Test`  process and deployments `Pre-Prod` and `Production`.    
5. Why are they different? -> Permissions.  `Pre-Prod` is refreshed from `Production` periodically and is used for staging and final verification.  `Pre-Prod` needs to be as close to `Production` as possible to help eliminate surprises.
6. What happens when the script fails to run? -> In `Development` and `Test`, the person who wrote the script ran the script, they would make the necessary adjustments and re-run it.  In `Pre-Prod` and `Production` the DBA notifies the requester of failure.  The requester debugs the script and makes the necessary tweaks.  They ask the DBA to run the script again.  
7. Why to scripts typically fail? -> Typically failures happen because each environment has different delta scripts.  A schema change or migration script is missed. 
8. Who reviews the scripts and when? -> The Database Developer and Lead Developer review the changes prior to going to `Pre-Prod`.   Because of the different delta scripts, the DBAs review the scripts prior to going to `Pre-Prod` as well as `Production` 
9. Who needs to be involved with each deployment? -> Deployments to `Development` and `Test` only involve the person making the change.  Deployments to `Pre-Prod` involve the requester, a database developer or lead developer, and the DBA.  Deployments to `Production` need everyone.  That is because each environment has a unique delta script, any issues require immediate fixing.
10. What isn't working and what needs to change? -> See below.

## What Needed To Change

The astute reader will notice a recurring theme in those answers.  

- Two different processes.
- Unique delta scripts per environment.
- Unique delta scripts meant it was difficult or near impossible to test.
- No mention of keeping track of changes and what needed to be deployed.
- Shared development environment.
- Reviews didn't happen until it was time to go to `Pre-Prod`.
- "All hands on deck" during `Production` deployments.

The application my team was responsible for had 700 tables.  All database access was done via stored procedures.  Including CRUD operations.  The database had roughly 5000 objects (tables, stored procedures, functions, etc).  All development was done on the same database.  When we did a release some changes were pushed while other changes were excluded.  We kept of which changes to include on a piece of paper.  This wasn't 20 years ago.  This was happening in 2014.

Those issues resulted in 2-4 hour `Production` deployments.  The fact of the matter was we didn't trust the process.  That lack of trust led intensive verification.  The actual deployment might be done in 20 minutes.  The remaining 100 minutes was spent verifying the deployment.  This included QA, the Business Owner, Business Analyst, Developers, Lead Developer, and Manager running various scenarios.  Even with all that effort, we still would miss some random thing that only 0.5% of our users would encounter.  

```
Roughly 50% of the time we had to do an emergency fix the next day due to a missed schema change.
```

## Draft Of Ideal Process

Drafting the ideal process took quite a bit of time.  This was caused by a lack of knowledge around what tooling can provide.  At the time, we knew about source control, build servers, and Redgate tooling.  We were all unfamiliar with what deployment tooling could provide.  Thankfully, Redgate was there to help educate us.

We first listed out the various tools and the functionality it provides.

- Source Control
    - Stores all SQL Scripts.
    - Is truth center of changes.
    - Includes ability to create branches for new features.
    - Provides ability to review changes prior to merge.    
- Database Tooling
    - Provides way to run scripts stored in source control on destination database.
    - Includes some sort of "preview" functionality to generate a review script.
- Build Server
    - Takes SQL Scripts from source control and packages them up.
    - Pushes package to deployment tool.
    - Can monitor multiple branches.
- Deployment Tool
    - Invokes database tooling to deploy database changes.
    - Uses database tooling to create a review script.
    - Provides auditing and approvals.
    - Used to deploy to all environments.
    - Has security features to allow for scenarios such as: only allowing DBAs to deploy to `Production`.

The tooling responsibilities are out to of the way.  We spent a great deal of time discussing shared database model vs dedicated database model.  Dedicated database model means each developer runs the database server on their own machine.  We ran into multiple problems using a shared database model.

- Database changes were made which stopped developers and QA from proceeding until code was updated.
- Two truth centers, the shared database which all changes were made to and then saved to source control, and source control.  If there was a conflict between source control and the shared database, which won?
- Unable to leverage branches effectively.  There can be 1 to N branches, but only 1 database.  
- Changes are made to a central database prior to review.  When should the review occur?
- Everyone used the same test data.  One person changing data affects multiple people on the team.

We decided to switch to dedicated databases.  In our case, it made a lot of sense.

We knew how the tooling worked and where changes would be made.  It was time to outline the ideal process.

1. Developer/Database Developer/Lead Developer creates branch.
2. All database changes and code changes are made on that branch.
3. Changes are completed and checked into the branch.
4. A merge request is created, which kicks off a build.  Build verifies the changes are valid SQL.
5. Database Developer or Lead Developer reviews database changes in merge request.  Provides feedback for fixes.
6. Branch is approved and merged.
7. Build Server kicks off build.  Verifies the changes are valid SQL and if they are, packages them up and pushes to Deployment Server.  Build Server tells Deployment Server to deploy to `Development`.
8. Deployment Server deploys to `Development`.
9. Developer/Database Developer/Lead Developer tells Deployment Server to deploy to `Test`.
10. Deployment Server deploys to `Test`.
11. Changes are verified in `Test`.
12. Developer/Database Developer/Lead Developer tells Deployment Server to deploy to `Pre-Prod`.  Deployment server uses database tooling to generate review script.
13. Deployment Server notifies DBA of deployment request to `Pre-Prod`.  They review the changes.  Provide feedback for fixes.
14. DBAs approve changes to `Pre-Prod`.
15. Deployment Server finishes deployment to `Pre-Prod`.
16. Changes are verified in `Pre-Prod`.  
17. A change request is submitted to the DBAs to promote a specific package in the deployment server to `Production`.
18. After hours, DBAs tells Deployment Server to deploy to `Production`.  Deployment server uses database tooling to generate review script.
19. DBAs review the script as a final sanity check.
20. Deployment Server finishes deployment to `Production`.

## Tooling

When coming up with that process, we purposely avoided tooling.  After we had a draft of that process, we start looking at the tooling.  First up was the tooling already being used.

- Build Server: TFS 2012 with some teams trying TeamCity.
- Source Control: The teams using TeamCity were using Git.  Everyone else was using TFS.
- Database Deployments: Teams have tried SSDT and RoundhousE in the past and failed, the team I was on had a working prototype with Redgate.
- Deployment Server: None, although at the time I thought Build Server = Deployment Server.

TFS 2012 was on its way out, it didn't make sense to continue to use that.  Redgate told us their tooling works with any build server, so we opted to leverage TeamCity for the pilot.  

Because we decided to use TeamCity, we decided to use Git.  In our case, our Git repo was stored in VSTS.  This was before VSTS had build or release pipelines.  

Redgate had flown out to help us.  We had a prototype working.  We did discuss SSDT and RoundhousE.  They failed for roughly the same reason.  95% of the people making the database changes did so in SQL Server Management Studio.  Too many people forgot to migrate those changes over to SSDT or RoundhousE.  Our discussion, along with the process we designed led to the following key requirements of the tooling:  

1. Can save database changes from SSMS.
2. Automatic detection of database changes.  
3. Majority of changes handled by tool (add column, delete column, change stored procedure) with the ability to have complex changes manually written and stored (move column to a new table).

RoundhousE met 1 out of the 3 (can save database changes from SSMS) and SSDT met 1 out of the 3 (majority of complex changes handled by the tool).  It made sense for us to continue to use Redgate with the pilot.

We didn't have a deployment server.  After the Redgate folks explained the benefits and features of Octopus Deploy, we did a quick POC using TeamCity, Redgate and Octopus Deploy.  The POC took about an hour to put together and showed a great deal of promise.  We decided to continue to use Octopus Deploy for the pilot.

## Implementing The Process

Anyone who has worked for a large development shop knows there are multiple projects being juggled.  During our kick off meeting we didn't know the web admins was looking at deployment servers as well.  They were currently focused on Release Management.  This was old school Release Management, before VSTS/VSO/Azure DevOps moved it into release pipelines.  It was right after Microsoft purchased InRelease and reskinned it to match Visual Studio.  

It didn't make sense to pilot multiple deployment servers.  We were asked to pause our implementation so we could land on the deployment server to Pilot.  After a few weeks, the decision was made to pilot Octopus Deploy.  The core reason was it use the same process across all environments.  The web admins were part of too many deployments which failed because something in the process wasn't tested in `Development` or `Test` or `Pre-Prod`.  

Once we landed on the deployment server to pilot it was off to the races.  The agreed upon process was put into place.  We did run into a couple of hiccups we didn't think about in the kick off meeting.

- Permissions -> what can the automated process do vs what can't it do.  We landed on preventing the process from creating new users and adding them to roles.  This way someone couldn't give themselves db_owner permissions in `Production`.
- Resolving the delta between all environments -> There were schema changes in `Production` not on `Development`.  The first time we tried to run the process in `Production` we almost wiped them out.  We quickly added that change into source control, rebuilt the package, and pushed it up through the environments to `Production`.  

## Speeding Up Deployments

Immediately, the number of emergency fixes due to a missing schema change dropped to zero.  That alone was a massive win.  

Because of that, the amount of time we spent verifying started dropping.  

1. 30 Minute Deployment, 90 Minute Verification
2. 25 Minute Deployment, 80 Minute Verification
3. 20 Minute Deployment, 70 Minute Verification
4. 15 Minute Deployment, 60 Minute Verification
5. 10 Minute Deployment, 50 Minute Verification
6. 5 Minute Deployment, 40 Minute Verification
7. 5 Minute Deployment, 30 Minute Verification

That in turn, made us want to deploy more often.  Frequent deployments means smaller changes.  Smaller changes meant less verification.  Less verification meant faster deployments.  Faster deployments meant we wanted to deploy more often.  The cycle continued until we got to 10 minute deployments.

## Early Adopters and Iterations

A couple of other teams (out of 9 remaining) saw what we were doing and they wanted in on the process.  They came on board as early adopters.  Having 3 teams use the process identified pain points and what needed to improve.  

- Not deploying what was approved -> I wasn't using the Redgate tooling correctly.  I was using a command to generate a preview for approval.  Then I ignored that preview and used a different command to directly deploy the package.  1 out of every 30 deployments ended up having an unexpected change made.  With a bit of research the correct commands were found and implemented.
- Saving the preview file to a file share -> I didn't know Octopus had the ability to save files as artifacts.  Artifacts can be downloaded by the approver from Octopus.  That was preferred over find the right file in the file share.  Small tweak to the script fixed that right up.
- DBAs being the bottleneck -> The three teams were deploying to `Pre-Prod` so often the DBAs couldn't keep up.  They also got tired of having to be online during deployments so they could approve the deployment to `Production`.  We switched it up so the process generated two files when deploying to `Pre-Prod`, one for `Pre-Prod`, one for `Production`.  The deployment would occur on `Pre-Prod` and they would approve everything after the fact.  We added a step to page them when a deployment failed in `Production`.  
- Developers not using their dedicated database -> There was no testing data in the developer's database.  So they pointed to `Test` to test their changes.  We solved that by creating a backup of the database in `Test` after each deployment.  Developers could restore that database to their local instance and they would have all the data they needed.  

```
No process be 100% perfect from the start.  Expect to iterate multiple times.  
```

## General Adoption

Eventually the time came for general adoption.  I was very surprised by the push back.  Specifically from the database developers.  So much of their time was spent generating deployment scripts.  So much so they thought that was key addition to the team.  The fear was this process was going to automate them out of a job.  That wasn't the case, the process was designed to eliminate all that wasted time generating and tweaking deployment scripts.  This freed them up to focus on important things like database structure, performance, reviewing changes and working on complex changes.  

Hindsight being what it is, what I should've done was:

- Schedule a meeting with the database developer and lead developer on the team to walk through the process.
- Schedule another meeting for the two of them to get an application's database into the process.
- Schedule a final meeting for them to teach their team how to use the process.  I would be in the background to answer questions.

But I didn't do that.  I combined all of that into one big meeting.  Live an learn.

## Conclusion

It took a lot of effort and time to automate database deployments.  In the end it was worth it.  Deployments to `Production` became a non-event.  The last `Production` deployment I did with that company involved myself, the business owner, and my manager.  We were online for 30 minutes.  25 of those minutes was spent telling funny stories and bad jokes.  The deployment went through with minimal fuss.  

In this article I focused on what we did to automate database deployments.  I didn't focus on on what we did.  The next article, released tomorrow, will focus on that.  

Until next time, Happy Deployments!